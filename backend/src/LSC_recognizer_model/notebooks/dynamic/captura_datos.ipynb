{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "from pathlib import __file__\n",
    "\n",
    "sys.path.insert(0, pathlib.Path().absolute().parent.parent.parent.__str__())\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), \"../../../../src\"))\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "from utils.holistic.holistic_detector import HolisticDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 20\n",
    "DURATION = 5\n",
    "\n",
    "signs = np.array([\"a veces\", \"abandonar\", \"abrazar\", \"abrigo\", \"abril\", \"aceptar\"])\n",
    "duration = FPS * DURATION\n",
    "\n",
    "start_folder = 1\n",
    "cant_videos_per_sign = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptiempo = 0\n",
    "\n",
    "# Crearemos el objeto\n",
    "holistic = HolisticDetector()\n",
    "\n",
    "# Leemos la cámara web\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for sign in signs:\n",
    "    for video_num in range(start_folder, start_folder+cant_videos_per_sign):\n",
    "        result_of_video = []\n",
    "        for frame_num in range(duration):\n",
    "\n",
    "            # Leemos el fotograma de la cámara\n",
    "            success, image = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            # Una vez que obtengamos la imagen la enviaremos\n",
    "            results = holistic.detect_holistic(image)\n",
    "            \n",
    "            # Dibujamos la predicción en el fotograma\n",
    "            image = holistic.draw_prediction(image, results)\n",
    "\n",
    "            # Mostramos los fps\n",
    "            ctiempo = time.time()\n",
    "            fps = 1 / (ctiempo - ptiempo)\n",
    "            ptiempo = ctiempo\n",
    "            cv2.putText(image, str(int(fps)), (image.shape[1]-100, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
    "\n",
    "            if frame_num == 0: \n",
    "                cv2.putText(image, 'STARTING COLLECTION', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(sign, video_num), (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                # Show to screen\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(500)\n",
    "            else: \n",
    "                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(sign, video_num), (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                # Show to screen\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "            pose, right_hand, left_hand, face = holistic.get_unprocessed_coordenates(results)\n",
    "            coords = [pose, right_hand, left_hand, face]\n",
    "            result_of_video.append(coords)\n",
    "\n",
    "            # Break gracefully\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "ptiempo = 0\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "writer= cv2.VideoWriter('basicvideo.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 20, (width,height))\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame= cap.read()\n",
    "\n",
    "\n",
    "    ctiempo = time.time()\n",
    "    fps = 1 / (ctiempo - ptiempo)\n",
    "    ptiempo = ctiempo\n",
    "    cv2.putText(frame, str(int(fps)), (frame.shape[1]-100, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "from utils.holistic.holistic_detector import HolisticDetector\n",
    "\n",
    "ptiempo = 0\n",
    "\n",
    "# Crearemos el objeto\n",
    "holistic = HolisticDetector()\n",
    "\n",
    "# Leemos la cámara web\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Leemos el fotograma de la cámara\n",
    "    success, image = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Una vez que obtengamos la imagen la enviaremos\n",
    "    results = holistic.detect_holistic(image)\n",
    "    \n",
    "    # Dibujamos la predicción en el fotograma\n",
    "    image = holistic.draw_prediction(image, results)\n",
    "\n",
    "    # Predicción\n",
    "    x = holistic.get_coordenates(results, used_parts=[\"pose\", \"right_hand\", \"left_hand\"])\n",
    "    try:\n",
    "        res = modelo.get_prediction(x, classes)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "\n",
    "    # Viz probabilities\n",
    "    image = holistic.probability_visualizer(res, classes, image)\n",
    "\n",
    "    # Mostramos los fps\n",
    "    ctiempo = time.time()\n",
    "    fps = 1 / (ctiempo - ptiempo)\n",
    "    ptiempo = ctiempo\n",
    "    cv2.putText(image, str(int(fps)), (image.shape[1]-100, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
    "\n",
    "    # Mostramos todo el fotograma modificado\n",
    "    cv2.imshow(\"holistic\", image)\n",
    "\n",
    "    # Break gracefully\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efdaa978e1c80e6f6818d5869b877c39bfa0ef86a38ae4e67259df164ba443df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
